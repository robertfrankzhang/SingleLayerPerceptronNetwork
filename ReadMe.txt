Note: This ReadMe is a direct, slightly less detailed transcript of my attached video. While you CAN read this, I think it would be far more informative and easy for you to just kick back, relax, and watch my extremely thorough demo video.

Transcript:
Hi Mrs. Elia! I am Robert Zhang from period two AP Computer Science. I created my final project using the Swift language in the Xcode IDE. Since the code runs a significant amount of calculations, I figured that it would be difficult for you to test it on your own if you don’t have an iPhone or an iOS developer account, since the Xcode emulator will run too slowly. So, I created this video that demos the entire project, and explains a bit of what is going on behind the scenes including basic explanations of the classes I created and the algorithms involved. Let’s get started!

To run the app, just click on the app icon. This takes you to the home screen, which is super straightforward. The home screen’s UI is created in the Home class, which is a subclass I created derived from the SKScene class in the SpriteKit Framework. Before we begin, you can click into the info button to view the very fundamental background of the app, and how to use it. There are 4 slides to this info section, which you can navigate by swiping the screen. The entire UI of the info section is created in the Info class, which is also a subclass of SKScene.

As you probably saw when I swiped through the info section, the user can see where they are in reading by the progress bar at the bottom. This progress bar is a custom class I created that is a subclass of the SKSpriteNode class from the SpriteKit framework. Inside this class are a bunch of methods and properties that make using such an object very easy. For example, in the Info class, I just call the Progress Bar instance’s move method, and the class handles everything on its own. Another feature I created for the Info screen’s UI are multiline labels. In Spritekit, text can typically only be created line by line. However, within my MultilineLabelNode class, I defined a static function that uses arrays and String slicing to convert a long string text from a label node into a multi line array of label nodes. This makes it easy for me to modify the text on the screen as an organized paragraph rather than adjusting things line by line.

On another note, next the to MultilineLabelNode class, you will see the Extensions class. Here, I wrote a bunch of class extensions that extend the functionality of certain Spritekit classes and make them easier to use. I also define a ThemeColor class, which just contains static variables representing consistent theme colors I can access throughout the code.

We will now go into the play screen. The play screen’s UI is created by the Play class, which is  again a subclass of SKScene. Like the other screen classes I defined, the Play class is event driven. The didMove method sets up the initial UI, while the swipe and touch functions change the screen upon a certain screen event, like a swipe or a tap. If you swipe, you can go between the Euclidean grid view where you’ll be able to see your training points, and the neural network view, where you’ll be able to see the weights and biases of your current neural network. This entire neural network view element is defined by the NetworkAnimation class I defined. Right now, since we haven’t placed any training points yet, and the network isn’t trained, this neural network has the weights as equal (aka zero), and the biases as 0. Later on, the weights will change in transparency depending on their importance relative to other weights. This is all handled within the NetworkAnimation class. The only thing that needs to be called from the Play class is the update method to update the network class’s graphics.

If we head back to the play screen, we can begin to place points. To place a point, I would click on the pattern bar on the top. This Pattern bar is created by my PatternsBar class, a subclass of SKSpriteNode which generates not only the bar’s UI displayed on the screen, but also the list of patterns used later. These colors generated will always be unique and easily differentiable, due to a color filtering algorithm defined in the PatternsBar class. A Pattern is defined as a class as well, with properties like color, name, outputVector, and isToggled. After I click on a color, I can now tap on the screen to place a colored dot with that pattern. For example, if I click on the xColor, I can place xColored dots on the screen. Then if I click on this other color, I can place this colored dot on the screen. Each dot is represented by a TrainingPointClass, which extends the functionality of the SKSpriteNode class with extra neural network properties patternType, normX, and normY. In total, you can place as many as 8 patterns on the screen, and as many dots as you want from those 8 patterns.

To start, we’ll just train these two colors. Press train. After a while, the neural network algorithm defined in the NeuralNet class would learn to find a set of weights and biases that can correctly classify the two patterns. These weights and biases can be translated into a line that can separate the patterns on the screen. This line is what we call a decision boundary. Every point on one side of the line will be classified by the neural network as one pattern, and every point on the other side of the line will be classified by the network as another pattern. As the network trains, you can see the lines rapidly training. When we swipe to the right, we can see the network currently trained by this array of points.

That was too easy! After all, this algorithm can train up to 8 patterns, and draw as many as 7 separating lines, creating outputs vectors up to 7 elements long. We’ve barely scratched the surface of what this app can do. So let’s do a few more training examples. We can reset the Euclidean space by pressing reset. You can try more!

It is important to note that while the neural network algorithm itself is relatively complex, the most complex algorithm implemented in my code is the linearly separable checking algorithm. Since this network is a single layer perceptron network, it can only classify linearly separable patterns. So, even before the network begins training, it needs to verify that everything the user placed is linearly separable, and it needs to also assign each pattern a valid output vector. Let’s show what this algorithm means by trying to place some points that are linearly inseparable. 

This algorithm was difficult to implement. If I tried to brute force the process of finding valid output vectors for placed patterns, every time you placed a point, the computer would have to search through 2 to the power of 7 permutation 7 calculative iterations to find, or 470 trillion iterations, with each iteration itself taking significant computation on its own. So, I needed to come up with a more efficient algorithm. Currently, this algorithm takes at maximum around 16000 iterations to complete, which is already a 30 billion times optimization, and for most points, it takes under 20 iterations to complete. All of these algorithms use an insane amount of array manipulation. This can all be found within the NeuralNet class.

Ultimately, I hoped to use this app to demonstrate the knowledge I learned from reading the neural network textbook, and also to provide a fun, graphic way to visualize how all neural networks work. 

Thanks!
